$ hostname
megatron.ftpn.ornl.gov
$ cat /etc/redhat-release
CentOS Linux release 7.2.1511 (Core)
$ git describe --always
nvl-c.hpdc2016-82-gfefb22d

$ git diff -U0 .
diff --git a/test/benchmarks/nvl-c/kernels/hashtable/hashtable.c b/test/benchmarks/nvl-c/kernels/hashtable/hashtable.c
index 1277f04..04505c4 100644
--- a/test/benchmarks/nvl-c/kernels/hashtable/hashtable.c
+++ b/test/benchmarks/nvl-c/kernels/hashtable/hashtable.c
@@ -25 +25,2 @@
-#define NVLFILE "_NVLFILEPATH_"
+//#define NVLFILE "_NVLFILEPATH_"
+#define NVLFILE "/opt/fio/scratch/jum/hashtable.nvl"



Execution times are sometimes as much as double as below, which are the
minimum times observed.  -txs3, -txs2, and -txs1 are all the same because
backup and clobber clauses are never specified.

$ rm -f /opt/fio/scratch/jum/hashtable.nvl && make -s hashtable-safe-refs-poor && LD_LIBRARY_PATH=../../../../../nvl/rt:/opt/proj-local/jum/pmem-git/src/debug ./hashtable-safe-refs-poor 1000
NUMELE = 1000
VALSIZE = 1
HEAPSIZE = 288000
NVLFILE = /opt/fio/scratch/jum/hashtable.nvl
Hashtable is created!
Store 1000 pairs of data with value size of 4!
Write time = 0.724566 sec
# of internal hash conflicts = 110
Replace 1000 pairs of data with value size of 4!
Replace time = 0.258442 sec
Retrieve 1000 pairs of data with value size of 4!
Found 1000 records
Read time = 0.000441 sec
Delete 1000 pairs of data!
Delete time = 0.071072 sec
# of deletes= 1000
Write+Replace+Read+Delete time = 1.054521 sec
Verification passed!

$ rm -f /opt/fio/scratch/jum/hashtable.nvl && make -s hashtable-safe-refs && LD_LIBRARY_PATH=../../../../../nvl/rt:/opt/proj-local/jum/pmem-git/src/debug ./hashtable-safe-refs 1000
NUMELE = 1000
VALSIZE = 1
HEAPSIZE = 288000
NVLFILE = /opt/fio/scratch/jum/hashtable.nvl
Hashtable is created!
Store 1000 pairs of data with value size of 4!
Write time = 0.723835 sec
# of internal hash conflicts = 110
Replace 1000 pairs of data with value size of 4!
Replace time = 0.261307 sec
Retrieve 1000 pairs of data with value size of 4!
Found 1000 records
Read time = 0.000481 sec
Delete 1000 pairs of data!
Delete time = 0.071856 sec
# of deletes= 1000
Write+Replace+Read+Delete time = 1.057479 sec
Verification passed!

$ rm -f /opt/fio/scratch/jum/hashtable.nvl && make -s hashtable-safe-refs-txs1-poor && LD_LIBRARY_PATH=../../../../../nvl/rt:/opt/proj-local/jum/pmem-git/src/debug ./hashtable-safe-refs-txs1-poor 1000
NUMELE = 1000
VALSIZE = 1
HEAPSIZE = 288000
NVLFILE = /opt/fio/scratch/jum/hashtable.nvl
Hashtable is created!
Store 1000 pairs of data with value size of 4!
Write time = 3.008251 sec
# of internal hash conflicts = 110
Replace 1000 pairs of data with value size of 4!
Replace time = 1.436378 sec
Retrieve 1000 pairs of data with value size of 4!
Found 1000 records
Read time = 0.000413 sec
Delete 1000 pairs of data!
Delete time = 1.442463 sec
# of deletes= 1000
Write+Replace+Read+Delete time = 5.887505 sec
Verification passed!

$ rm -f /opt/fio/scratch/jum/hashtable.nvl && make -s hashtable-safe-refs-txs1 && LD_LIBRARY_PATH=../../../../../nvl/rt:/opt/proj-local/jum/pmem-git/src/debug ./hashtable-safe-refs-txs1 1000
NUMELE = 1000
VALSIZE = 1
HEAPSIZE = 288000
NVLFILE = /opt/fio/scratch/jum/hashtable.nvl
Hashtable is created!
Store 1000 pairs of data with value size of 4!
Write time = 2.997890 sec
# of internal hash conflicts = 110
Replace 1000 pairs of data with value size of 4!
Replace time = 1.443836 sec
Retrieve 1000 pairs of data with value size of 4!
Found 1000 records
Read time = 0.000522 sec
Delete 1000 pairs of data!
Delete time = 1.433930 sec
# of deletes= 1000
Write+Replace+Read+Delete time = 5.876178 sec
Verification passed!



Adding the following shows that all allocations are freed in all of
the above cases:

diff --git a/test/benchmarks/nvl-c/kernels/hashtable/hashtable.c b/test/benchmarks/nvl-c/kernels/hashtable/hashtable.c
index 1277f04..c58cf68 100644
--- a/test/benchmarks/nvl-c/kernels/hashtable/hashtable.c
+++ b/test/benchmarks/nvl-c/kernels/hashtable/hashtable.c
@@ -584,2 +585,5 @@ void ht_del( const char *key ) {
 
+size_t nvlrt_get_numAllocNV();
+size_t nvlrt_get_numFreeNV();
+
 int main( int argc, char **argv ) {
@@ -666,2 +670,10 @@ int main( int argc, char **argv ) {
        }
+#if POOR
+        hashtable = NULL;
+#else
+        hashtable_nv = NULL;
+#endif
+        nvl_set_root(heap, 0);
+        printf("nallocs=%zu\n", nvlrt_get_numAllocNV());
+        printf("nfrees=%zu\n", nvlrt_get_numFreeNV());



To check overhead of automatic reference counting:

$ rm -f /opt/fio/scratch/jum/hashtable.nvl && make -s hashtable-safe-norefs-poor && LD_LIBRARY_PATH=../../../../../nvl/rt:/opt/proj-local/jum/pmem-git/src/debug ./hashtable-safe-norefs-poor 1000
NUMELE = 1000
VALSIZE = 1
HEAPSIZE = 288000
NVLFILE = /opt/fio/scratch/jum/hashtable.nvl
Hashtable is created!
Store 1000 pairs of data with value size of 4!
Write time = 0.323789 sec
# of internal hash conflicts = 110
Replace 1000 pairs of data with value size of 4!
Replace time = 0.108172 sec
Retrieve 1000 pairs of data with value size of 4!
Found 1000 records
Read time = 0.000168 sec
Delete 1000 pairs of data!
Delete time = 0.000158 sec
# of deletes= 1000
Write+Replace+Read+Delete time = 0.432287 sec
Verification passed!



Automatic Shadow Updates
------------------------

Shadow updates are not performed because, according to our cost model, the
largest allocations are too small (just three NVM pointers wide) relative to
the constant baseline overhead of a shadow update.

Because our automatic shadow update implementation does not currently
support allocations containing pointers, we cannot measure the execution
time of hashtable with automatic shadow updates.
